I am working on a project to track how long my child is playing the piano using various technologies. I have a Wyze V3 camera that provides an RTSP stream of the piano area. My goal is to use this video stream to detect when my child is sitting at the piano and actively playing, using both audio and pose detection techniques. I want to build a solution that is flexible, maintainable, and adheres to software engineering best practices.

Technologies Being Used:

Wyze V3 camera: Provides RTSP video stream.
Python: For scripting and implementation.
FFmpeg and PyDub: For audio detection (detecting piano sounds from the RTSP stream).
OpenCV (cv2.VideoCapture): For capturing the video stream from the camera.
MediaPipe: For detecting pose landmarks in the video stream.
Home Assistant: Running on a server for logging, visualization, and automation based on detected piano playing.
Requirements:

Pose Detection: The system should detect when my child is in a "playing piano" pose, not just sitting at the piano.
Audio Detection: Detect the sound of the piano being played using FFmpeg and PyDub.
Buffer Time: Include a buffer (e.g., 30 seconds to 1 minute) to account for brief interruptions, such as page turns.
Data Storage: Store playing time data for later analysis and visualization.
Integration with Home Assistant: Make the playing time easily visible in Home Assistant.
Maintainability: The code should be modular, follow Python best practices, and adhere to SOLID programming principles.
Extensibility: The system should be designed to allow for easy modifications and extensions, such as adding new detection methods or stream sources.
Current Challenges:

The system is not storing the detected playtime data anywhere.
There's no integration with Home Assistant yet.
There is no "main" script or driver tying everything together, leading to disjointed components.
Expected Output: Generate a Python-based solution that addresses the above requirements. 

The solution should include:

A modular design following SOLID principles.
A well-structured "main" script that coordinates the pose detection, audio detection, and timing logic.
Integration points for storing data and updating Home Assistant.
Clear and maintainable code with appropriate error handling and logging.
A solid, straight-forward, bug-free way to process the stream for audio and video without building up a huge lag and getting the wrong results.

The RTSP stream URL can be found in the environment variable `RTSP_URL`.
The HomeAssistant URL can be found in the environment variable `HA_URL`


######################

I need help designing and writing a Python-based system that processes an RTSP stream for both audio and video detection services, adhering to SOLID principles and clean, production-ready code. Ensure "secrets" are read from the system's environment variables.
The entire goal of this program is to detect whether a child is playing piano and for how long.

Requirements:

The system will have an RTSP stream (URL provided in an env variable).
An audio detection service will be written to detects whether a piano is being played.
A pose detection service will be written, which detects if someone is sitting at the piano.

A central monitor consumes detection results from processing the audio and video and sends updates to external systems (specifically, Home Assistant).
The system should be modular, extensible, and follow Python best practices, including proper error handling, logging, and testability.
Key Design Decisions:
There is one RTSP stream coming from a Wyze camera.
The Wyze camera is streaming audio in the pcm_alaw format at 16,000 Hz.
Adhere to SOLID principles (SRP, OCP, LSP, ISP, DIP) and Python best practices, making the code easily maintainable, testable, and extensible.
Ensure that the processing of the audio and video is bug-free and robust. There is a single RTSP stream. Ensure that handling it is resilient, efficient, and responsive. If queues are used, ensure they don't fill, and if they do, make sure that the freshest data is put into them and overwrite the old data.
If there is multithreading or multiprocessing or any other kind of concurrent programming, ensure that it is done correctly and thoughtfully and only if necessary.
Testing the pose detection should be possible separately from the audio detection.
Testing the audio detection should be possible separately from the pose detection.
The real code should be able to be run to test each processing separately using the real RTSP stream.

Additional Considerations:
Ensure the code has proper logging and error handling to make it production-ready.
The system should be scalable, so consider a design that can accommodate future additions (e.g., adding new detection methods or integrating with other external systems).
Focus on clean, readable, testable code, and provide clear documentation and comments.
Please provide well-structured Python code with appropriate comments that follows these principles.
When there are multiple files, break out the code into each individual file.  Do not put all of the code into a single file.
The RTSP stream URL can be found in the environment variable `RTSP_URL`.
The HomeAssistant URL can be found in the environment variable `HA_URL`
When pressing CTRL+c on the keyboard, the program should exit.

Do not mock out the functions with the one exception of writing the result to HomeAssistant.  
* The RTSPStream needs to actually get the audio from the stream and detect if a piano is being played. 
* The DetectionMonitor needs to work as if the audio and pose detectors were real, because they are.
* The PoseDetectionApp needs to actually get real video from the RTSP stream and detect a pose of shoulders being above a waist.
* The AudioDetectionApp needs to actually get real audio from the stream and process it to determine if a piano is being played.

